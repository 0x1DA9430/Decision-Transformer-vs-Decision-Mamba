batch_size: 256
context_length: 10
conv_proj: false
conv_window_size: 6
data_dir_prefix: ./data/data_atari/
epochs: 5
experiment: dtrans_seaquest
game: Seaquest
learning_rate: 0.0006
log_to_mlflow: false
log_to_wandb: false
model_type: reward_conditioned
n_embd: 128
n_head: 8
n_layer: 6
num_buffers: 50
num_steps: 500000
output: ./output/context_10_rtg_5max/atari_seaquest_eddie/
seed: 132
token_mixer: attn
trajectories_per_buffer: 10
