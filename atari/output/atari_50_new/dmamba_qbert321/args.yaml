batch_size: 256
context_length: 50
conv_proj: false
conv_window_size: 6
data_dir_prefix: ./data/data_atari/
epochs: 5
experiment: dmamba_qbert
game: Qbert
learning_rate: 0.0006
log_to_mlflow: false
log_to_wandb: false
model_type: reward_conditioned
n_embd: 128
n_head: 8
n_layer: 6
num_buffers: 50
num_steps: 500000
output: ./output/context_50_rtg_5max/atari_qbert_eddie/
seed: 321
token_mixer: mamba
trajectories_per_buffer: 10
