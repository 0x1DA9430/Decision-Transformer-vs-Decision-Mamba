Analyzing data for game: Seaquest
Total steps analyzed: 5000000
Number of trajectories: 3538
Visualizing a random game state:

Action space analysis:
Total actions: 5000000
Unique actions: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
Number of unique actions: 18

Action frequency breakdown:
Action 0: 216203 times (4.32%)
Action 1: 246075 times (4.92%)
Action 2: 253533 times (5.07%)
Action 3: 218658 times (4.37%)
Action 4: 203363 times (4.07%)
Action 5: 260174 times (5.20%)
Action 6: 259064 times (5.18%)
Action 7: 241626 times (4.83%)
Action 8: 274479 times (5.49%)
Action 9: 266105 times (5.32%)
Action 10: 299942 times (6.00%)
Action 11: 306514 times (6.13%)
Action 12: 288222 times (5.76%)
Action 13: 316080 times (6.32%)
Action 14: 331500 times (6.63%)
Action 15: 297132 times (5.94%)
Action 16: 371832 times (7.44%)
Action 17: 349498 times (6.99%)

Action distribution entropy: 4.1510
Max possible entropy: 4.1699
Normalized entropy: 0.9955

Reward sequence analysis:
Average trajectory length: 1413.12
Average total reward per trajectory: 61.45
Maximum return: 277.00
Average steps until first non-zero reward: 87.23

Frame complexity analysis:
entropy: 2.2405 +/- 0.0201
edge_ratio: 0.0842 +/- 0.0035
compression_ratio: 12.9174 +/- 0.4186
ssim: 0.9620 +/- 0.0087
feature_count: 16.1771 +/- 1.5200