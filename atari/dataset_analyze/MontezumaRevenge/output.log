Analyzing data for game: MontezumaRevenge
Total steps analyzed: 5000000
Number of trajectories: 2831
Visualizing a random game state:

Action space analysis:
Total actions: 5000000
Unique actions: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]
Number of unique actions: 18

Action frequency breakdown:
Action 0: 150897 times (3.02%)
Action 1: 308143 times (6.16%)
Action 2: 366377 times (7.33%)
Action 3: 302558 times (6.05%)
Action 4: 604970 times (12.10%)
Action 5: 199131 times (3.98%)
Action 6: 569020 times (11.38%)
Action 7: 225808 times (4.52%)
Action 8: 287929 times (5.76%)
Action 9: 167165 times (3.34%)
Action 10: 50018 times (1.00%)
Action 11: 114869 times (2.30%)
Action 12: 249056 times (4.98%)
Action 13: 108724 times (2.17%)
Action 14: 601887 times (12.04%)
Action 15: 191027 times (3.82%)
Action 16: 201432 times (4.03%)
Action 17: 300989 times (6.02%)

Action distribution entropy: 3.9404
Max possible entropy: 4.1699
Normalized entropy: 0.9450

Reward sequence analysis:
Average trajectory length: 1763.91
Average total reward per trajectory: 0.00
Maximum return: 0.00
No non-zero rewards found in the analyzed trajectories.
